{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d94817-f458-49b4-aadc-87a7a8cb0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "import gseapy as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import swan_vis as swan\n",
    "import yaml\n",
    "from snakemake.io import expand\n",
    "\n",
    "p = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(p)\n",
    "\n",
    "from scripts.utils import *\n",
    "from scripts.plotting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f1f948-c515-4ef4-897d-e0454c5c291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../snakemake/config.yml'\n",
    "with open(config_file) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5562e3c9-eb5a-4560-836c-d4284b633299",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = '../'+expand(config['data']['ab'], species='human')[0]\n",
    "filt_ab = '../'+expand(config['data']['filt_ab'], species='human')[0]\n",
    "read_annot = '../'+expand(config['data']['read_annot'], species='human')[0]\n",
    "t_metadata = '../'+expand(config['ref']['cerberus']['t_info'], species='human')[0]\n",
    "lib_meta = '../'+expand(config['data']['meta'], species='human')[0]\n",
    "swan_file = '../'+expand(config['data']['sg'], species='human')[0]\n",
    "cerberus_h5 = '../'+expand(config['data']['cerb_annot'], species='human')[0]\n",
    "cerb_t_metadata = '../'+expand(config['data']['t_info'], species='human')[0]\n",
    "major_isos = '../'+expand(config['data']['major_isos'], species='human', obs_col='sample')[0]\n",
    "pi_tpm_table = '../'+expand(config['data']['pi_tpm']['triplet'], species='human', obs_col='sample')[0]\n",
    "pp_summary = '../'+expand(config['data']['p_pred']['summary'], species='human')[0]\n",
    "ref_t_metadata = '../'+expand(config['ref']['t_info'], species='human')[0]\n",
    "ref_g_metadata = '../'+expand(config['ref']['g_info'], species='human')[0]\n",
    "\n",
    "introp_bed = '../'+expand(config['intropolis']['bed'], species='human')[0]\n",
    "\n",
    "ver = 'v40_cerberus'\n",
    "min_tpm = 1\n",
    "gene_subset = 'polya'\n",
    "obs_col = 'sample'\n",
    "go_gene_subset = 'protein_coding'\n",
    "predom_iso_subset = 'protein_coding'\n",
    "\n",
    "m_lib_meta = '../'+expand(config['data']['meta'], species='mouse')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c61b8a82-29b4-4504-b5ba-72551c299f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_table(df):\n",
    "    \"\"\"\n",
    "    Get a melted form table for each entry in a tss, ic, or tes table\n",
    "    for each form of support for each triplet feature.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pandas DataFrame): DataFrame of tsss, ics, or tess\n",
    "    \n",
    "    Returns:\n",
    "        df (pandas DataFrame): Long-form DataFrame of support for each tss, ic, or tes\n",
    "    \"\"\"\n",
    "    keep_cols = ['Name', 'source']\n",
    "    df = ic[keep_cols].copy(deep=True)\n",
    "    df['list_source'] = df.source.str.split(',')\n",
    "    df = df.explode('list_source')\n",
    "    df.drop('source', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# chatgpt wrote this for me thanx chatgpt\n",
    "def sequential_pairs(x):\n",
    "    \"\"\"\n",
    "    Get sequential pairs of tuples in list.\n",
    "    Example: [1,2,3,4] -> [(1,2),(3,4)]\n",
    "    \"\"\"\n",
    "    p = []\n",
    "    for i in range(0, len(x) - 1, 2):\n",
    "        p.append((x[i], x[i + 1]))\n",
    "    return p\n",
    "\n",
    "def explode_ic(ic):\n",
    "    \"\"\"\n",
    "    Explode an ic df to long form with splice junction entries\n",
    "    \"\"\"\n",
    "    # remove the monoexonic entries\n",
    "    ic = ic.loc[~(ic.Coordinates == '-')]\n",
    "    \n",
    "    # explode into series of ss coords\n",
    "    keep_cols = ['Chromosome', 'Coordinates',\n",
    "                 'Strand', 'gene_id',\n",
    "                 'Name']\n",
    "    df = ic.copy(deep=True)\n",
    "    df = df[keep_cols]\n",
    "    df['ss_coords'] = df.Coordinates.str.split('-')\n",
    "    \n",
    "    # get pairs of sss to form sjs\n",
    "    df['sj_coords'] = df.ss_coords.apply(sequential_pairs)\n",
    "    df = df.explode('sj_coords')\n",
    "    df.drop(['Coordinates', 'ss_coords'], axis=1, inplace=True)\n",
    "                \n",
    "    return df\n",
    "\n",
    "def get_ss_sj_from_ic(ic, ref_sources, how):\n",
    "    ic = ic.copy(deep=True)\n",
    "\n",
    "    # get coords of each splice site in each splice junction\n",
    "    df = explode_ic(ic)\n",
    "    df['Start'] = df['sj_coords'].str[0].astype(int)\n",
    "    df['End'] = df['sj_coords'].str[1].astype(int)\n",
    "    df.drop('sj_coords', axis=1, inplace=True)\n",
    "\n",
    "    # label sss as 5' or 3' and melt\n",
    "    if how == 'ss':\n",
    "        assert len(df.loc[(df.Start>df.End)&(df.Strand=='+')].index) == 0\n",
    "        # since these are intron coords, the start defines a 3' ss \n",
    "        # and the end defines a 5' ss\n",
    "        df.rename({'Start':'ss_3', 'End':'ss_5'}, axis=1, inplace=True)\n",
    "        id_cols = ['Chromosome', 'Strand', 'gene_id', 'Name']\n",
    "        df = df.melt(id_vars=id_cols,\n",
    "                     var_name='ss_type',\n",
    "                     value_name='Start')\n",
    "        \n",
    "    # for sjs, reorder according to min and max coords\n",
    "    # in bed standard format\n",
    "    elif how == 'sj':\n",
    "        df['temp_Start'] = df.Start\n",
    "        df['temp_End'] = df.End\n",
    "        df['Start'] = df[['temp_Start', 'temp_End']].min(axis=1)\n",
    "        df['End'] = df[['temp_Start', 'temp_End']].max(axis=1)\n",
    "        df.drop(['temp_Start', 'temp_End'], axis=1, inplace=True)\n",
    "        \n",
    "    # merge source info in w/ coord info\n",
    "    df2 = get_source_table(ic)\n",
    "    df = df.merge(df2, how='left', on=['Name'])\n",
    "\n",
    "    # figure out novelty and source of each ss / sj\n",
    "    df.drop('Name', axis=1, inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    gb_cols = ['Chromosome', 'Strand', 'gene_id', 'Start']\n",
    "    if how == 'ss':\n",
    "        gb_cols += ['ss_type']\n",
    "    elif how == 'sj':\n",
    "        gb_cols += ['End']\n",
    "    df.rename({'list_source': 'source'},\n",
    "              axis=1, inplace=True)\n",
    "    df['novelty'] = df.source.isin(ref_sources).map({True: 'Known',\n",
    "                                                     False: 'Novel'})\n",
    "    df = df.groupby(gb_cols).agg(','.join).reset_index()\n",
    "    df = cerberus.update_novelty(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_sj_from_ic(ic, ref_sources):\n",
    "    \"\"\"\n",
    "    Get a splice junction table from an intron chain table.\n",
    "    Retain source and novelty information.\n",
    "    \n",
    "    Parameters:\n",
    "        ic (pandas DataFrame): DataFrame formatted as cerberus ic table\n",
    "        ref_sources (list of str): List of sources to use as references\n",
    "        \n",
    "    Returns:\n",
    "        df (pandas DataFrame): DataFrame with entries for each splice junction\n",
    "    \"\"\"\n",
    "    return get_ss_sj_from_ic(ic, ref_sources, 'sj')\n",
    "\n",
    "def get_ss_from_ic(ic, ref_sources):\n",
    "    \"\"\"\n",
    "    Get a splice site table from an intron chain table.\n",
    "    Retain source and novelty information.\n",
    "    \n",
    "    Parameters:\n",
    "        ic (pandas DataFrame): DataFrame formatted as cerberus ic table\n",
    "        ref_sources (list of str): List of sources to use as references\n",
    "        \n",
    "    Returns:\n",
    "        df (pandas DataFrame): DataFrame with entries for each splice site\n",
    "    \"\"\"\n",
    "    return get_ss_sj_from_ic(ic, ref_sources, 'ss')       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0aefda-b043-4072-8845-c1bbfbaca2a8",
   "metadata": {},
   "source": [
    "## Get table of support / splice junction by intropolis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfa4841-5a38-41c1-b2bf-0878fe8acef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sources = ['v29', 'v40']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4ae51d8-62f7-468e-a882-06b2c0d6fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first make tables for the different splice junctions and splice sites; determine their novelty\n",
    "ca = cerberus.read(cerberus_h5)\n",
    "ic = ca.ic.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28763856-1096-406a-aa60-6135b7ca3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_sj_from_ic(ca.ic, ref_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "158dde4a-1d42-4d74-ad3f-81f3a34f5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read intropolis \n",
    "i_df = pr.read_bed(introp_bed).df\n",
    "source = 'intropolis'\n",
    "i_df['source'] = source\n",
    "i_df = i_df.loc[i_df.Start.notnull()]\n",
    "i_df[source] = True\n",
    "\n",
    "keep_cols = ['Chromosome', 'Start', 'End', 'Strand', 'intropolis']\n",
    "i_df = i_df[keep_cols].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80c098e4-f341-4f39-b767-1a1a38badb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intropolis</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>29650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>423917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Start\n",
       "intropolis        \n",
       "False        29650\n",
       "True        423917"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge in\n",
    "df = df.merge(i_df[keep_cols],\n",
    "                how='left',\n",
    "                on=['Chromosome', 'Start', 'End', 'Strand'])\n",
    "temp[source] = temp[source].fillna(False)\n",
    "temp[['Start', 'intropolis']].groupby('intropolis').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "456c2bfa-1208-45b2-812b-79a15b7e69dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>novelty</th>\n",
       "      <th>intropolis</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Known</th>\n",
       "      <th>False</th>\n",
       "      <td>24783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>383883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Novel</th>\n",
       "      <th>False</th>\n",
       "      <td>4867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>40034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Start\n",
       "novelty intropolis        \n",
       "Known   False        24783\n",
       "        True        383883\n",
       "Novel   False         4867\n",
       "        True         40034"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp[['novelty', 'intropolis', 'Start']].groupby(['novelty', 'intropolis']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848bfb6-3e79-4c07-9716-d3a4dd227bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
